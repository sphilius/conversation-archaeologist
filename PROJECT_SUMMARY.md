# Claude Conversation Extractor - Project Summary & AI Agent Prompts

## ğŸ¯ Project Overview

**Claude Conversation Extractor** is a production-ready Python CLI tool that extracts complete conversation data from Claude.ai, including messages, branches, artifacts, tool calls, thinking content, and metadata. It exports in two formats:
- **LLM-Optimized JSON**: Flat structure perfect for RAG systems and AI processing
- **Human-Friendly Markdown**: Beautiful reports with statistics and visualizations

## ğŸ“ Complete File Structure

```
claude-conversation-extractor/
â”œâ”€â”€ README.md                    # Main documentation
â”œâ”€â”€ QUICKSTART.md                # 5-minute getting started guide
â”œâ”€â”€ AI_AGENT_PROMPTS.md          # Prompts for AI coding agents
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ setup.py                     # Package setup
â”œâ”€â”€ pyproject.toml               # Modern Python tooling config
â”œâ”€â”€ requirements.txt             # Production dependencies
â”œâ”€â”€ requirements-dev.txt         # Development dependencies
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ src/claude_extractor/        # Main package
â”‚   â”œâ”€â”€ __init__.py             # Package initialization
â”‚   â”œâ”€â”€ __main__.py             # Module entry point
â”‚   â”œâ”€â”€ cli.py                  # Click-based CLI (400+ lines)
â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # Pydantic data models
â”‚   â”‚   â””â”€â”€ __init__.py        # Conversation, Message, Artifact, Branch models
â”‚   â”‚
â”‚   â”œâ”€â”€ extractors/             # Extraction strategies
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ hybrid_extractor.py # Browser automation + API (300+ lines)
â”‚   â”‚
â”‚   â”œâ”€â”€ parsers/                # Data parsing (placeholder)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ exporters/              # Export formats
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ json_exporter.py   # LLM-optimized JSON
â”‚   â”‚   â””â”€â”€ markdown_exporter.py # Human-friendly Markdown
â”‚   â”‚
â”‚   â”œâ”€â”€ analyzers/              # Conversation analysis
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ conversation_analyzer.py # Topic detection, complexity scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ auth/                   # Authentication (placeholder)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py          # Loguru-based logging
â”‚
â”œâ”€â”€ examples/                   # Usage examples
â”‚   â””â”€â”€ basic_extraction.py    # Basic usage as library
â”‚
â”œâ”€â”€ tests/                      # Test suite (to be implemented)
â”‚   â””â”€â”€ __init__.py
â”‚
â””â”€â”€ docs/                       # Documentation (to be created)
```

## ğŸ”‘ Key Features Implemented

### âœ… Core Functionality
- **Hybrid Extraction**: Browser automation with Playwright (API extraction is TODO)
- **Data Models**: Complete Pydantic models with type safety
- **JSON Export**: LLM-optimized flat structure
- **Markdown Export**: Beautiful human-readable reports with Mermaid diagrams
- **CLI Interface**: Rich Click-based UI with progress bars and colors
- **Configuration**: YAML-based config with Pydantic validation
- **Logging**: Loguru with colors and file output

### âš ï¸ TODO/Placeholders
- API-based extraction (requires reverse engineering Claude's API)
- Advanced conversation analysis (NLP-based topic extraction)
- Authentication manager with keyring integration
- Comprehensive test suite
- Additional export formats (Obsidian, Notion, HTML)
- Real-time monitoring mode
- Multi-conversation comparison

## ğŸš€ Installation & Usage

### Quick Install
```bash
git clone <repo>
cd claude-conversation-extractor
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
pip install -e .
playwright install chromium
```

### Basic Usage
```bash
# Set authentication
export CLAUDE_SESSION_KEY="your_session_cookie"

# Extract a conversation
claude-extract https://claude.ai/chat/YOUR_CONVERSATION_ID

# With options
claude-extract URL --output-dir ./exports --format both --verbose
```

### As Python Library
```python
from claude_extractor.extractors.hybrid_extractor import HybridExtractor
from claude_extractor.exporters.json_exporter import JSONExporter

extractor = HybridExtractor(auth_cookie="your_cookie")
conversation = extractor.extract("https://claude.ai/chat/ID")

exporter = JSONExporter()
exporter.export(conversation, "./output.json")
```

## ğŸ¤– AI Agent Prompts

### Master Context Prompt for All AI Agents

```markdown
You are working on the Claude Conversation Extractor, a Python CLI tool for extracting and exporting Claude.ai conversations.

PROJECT STATUS:
- Production-ready core extraction via Playwright browser automation
- Complete Pydantic data models with type safety
- JSON (LLM-optimized) and Markdown (human-friendly) exporters
- Rich CLI with Click, progress bars, and colored output
- Configuration system with YAML and Pydantic
- Structured logging with Loguru

ARCHITECTURE:
- Models: Pydantic schemas in src/claude_extractor/models/
- Extractors: Hybrid strategy (API + browser) in extractors/
- Exporters: JSON and Markdown in exporters/
- CLI: Click-based interface in cli.py
- Config: YAML + Pydantic in config.py

KEY DESIGN PRINCIPLES:
1. Type safety: Use Python type hints everywhere
2. Two audiences: LLM-friendly JSON + human-friendly Markdown
3. Hybrid extraction: Try multiple strategies (API first, browser fallback)
4. Rich UX: Progress bars, colors, helpful error messages
5. Extensibility: Plugin-ready architecture

CODE STANDARDS:
- Black formatting (line length 100)
- isort for import sorting
- Type hints on all functions
- Google-style docstrings
- Loguru for logging
- Pydantic for validation
- pytest for testing

CURRENT TODO LIST:
1. Implement API-based extraction (_extract_via_api in hybrid_extractor.py)
2. Add comprehensive test suite (pytest)
3. Enhance conversation analysis (NLP-based topics)
4. Add more export formats (Obsidian, Notion, HTML)
5. Implement authentication manager with keyring
6. Add real-time monitoring mode
7. Create multi-conversation comparison tool
8. Write comprehensive documentation

When making changes:
- Maintain type safety with mypy
- Follow existing patterns
- Add logging for all operations
- Write docstrings for public APIs
- Update tests for new features
- Document in README/QUICKSTART
```

### Specific Task Prompts

#### 1. Implement API Extraction

```markdown
TASK: Implement _extract_via_api() method in hybrid_extractor.py

REQUIREMENTS:
- Research Claude.ai's internal API endpoints using browser DevTools
- Implement authentication with session cookie
- Parse API responses into Conversation model
- Handle pagination and rate limiting
- Add retry logic with exponential backoff
- Fall back to browser extraction if API fails
- Log all API calls at DEBUG level

ACCEPTANCE CRITERIA:
- API extraction is faster than browser (< 2 seconds)
- All data matches browser extraction output
- Handles errors gracefully
- Works with/without authentication

FILES TO MODIFY:
- src/claude_extractor/extractors/hybrid_extractor.py

TESTING:
- Test with real conversations (small, medium, large)
- Test with expired authentication
- Test with rate limiting
- Compare outputs with browser extraction
```

#### 2. Add Comprehensive Tests

```markdown
TASK: Create complete test suite with pytest

STRUCTURE:
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_models.py          # Test Pydantic models
â”‚   â”œâ”€â”€ test_exporters.py       # Test JSON/Markdown export
â”‚   â”œâ”€â”€ test_config.py          # Test configuration
â”‚   â””â”€â”€ test_cli.py             # Test CLI commands
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_extraction.py      # Test full extraction pipeline
â”‚   â””â”€â”€ test_end_to_end.py      # Test complete workflow
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ sample_conversation.json
â”‚   â””â”€â”€ sample_page.html
â””â”€â”€ conftest.py                 # Pytest configuration

REQUIREMENTS:
- Unit tests for each model with edge cases
- Mock Playwright for browser tests
- Test CLI with Click's testing utilities
- Achieve >80% code coverage
- Use pytest-asyncio for async tests
- Add fixtures for reusable test data

RUN WITH:
pytest --cov=claude_extractor --cov-report=html
pytest -v tests/unit/
```

#### 3. Enhance Conversation Analysis

```markdown
TASK: Add NLP-based conversation analysis

NEW FILE: src/claude_extractor/analyzers/nlp_analyzer.py

FEATURES:
1. Topic Extraction:
   - Use sentence transformers for semantic clustering
   - Identify 3-7 main topics
   - Track topic transitions
   
2. Complexity Scoring:
   - Technical terminology density
   - Information density (ideas per message)
   - Branching complexity
   - Tool usage patterns
   
3. Decision Points:
   - Identify branch points
   - Flag clarifying questions
   - Note topic pivots

DEPENDENCIES TO ADD:
- sentence-transformers
- spacy
- scikit-learn

OUTPUT FORMAT:
{
  "topics": [{"name": str, "weight": float, "messages": List[str]}],
  "complexity": {"score": float, "factors": Dict[str, float]},
  "decision_points": [{"message_id": str, "type": str}]
}

INTEGRATION:
- Add to ConversationAnalyzer class
- Include in Markdown reports
- Add to JSON exports as optional field
```

#### 4. Add Export Formats

```markdown
TASK: Implement Obsidian, Notion, and HTML exporters

NEW FILES:
- src/claude_extractor/exporters/obsidian_exporter.py
- src/claude_extractor/exporters/notion_exporter.py
- src/claude_extractor/exporters/html_exporter.py

OBSIDIAN EXPORTER:
- Create markdown with frontmatter (YAML metadata)
- Generate index file linking all conversations
- Use Obsidian-specific features (backlinks, tags)
- Support nested folders

NOTION EXPORTER:
- Use Notion API to create pages
- Preserve formatting (code blocks, quotes)
- Organize in databases
- Support nested pages for branches

HTML EXPORTER:
- Generate standalone HTML with embedded CSS
- Add syntax highlighting (use Prism.js)
- Include search functionality
- Make responsive (mobile-friendly)

CLI INTEGRATION:
claude-extract URL --format obsidian
claude-extract URL --format notion --notion-token TOKEN
claude-extract URL --format html --output index.html
```

#### 5. Performance Optimization

```markdown
TASK: Optimize extraction speed and memory usage

BOTTLENECKS TO ADDRESS:
1. Browser startup/shutdown overhead
2. Waiting for page load (5-10 seconds)
3. Memory growth with large conversations
4. No caching of intermediate results

OPTIMIZATIONS:
1. Browser Instance Reuse:
   - Keep browser open across extractions
   - Use browser contexts for isolation
   - Implement connection pooling
   
2. Lazy Loading:
   - Load messages in chunks
   - Stream large artifacts to disk
   - Use generators instead of lists
   
3. Caching:
   - Cache API responses (TTL-based)
   - Store partial extractions
   - Resume interrupted extractions
   
4. Parallel Processing:
   - Extract multiple conversations concurrently
   - Use asyncio properly
   - Limit concurrent operations

TARGET METRICS:
- 50-message conversation in <3 seconds
- Support 500+ message conversations
- Memory usage <200MB
- Batch extract 10 conversations in <30 seconds

BENCHMARKING:
- Add --benchmark flag to CLI
- Track: time per message, memory, API calls
- Profile with py-spy or cProfile
```

### General Development Workflow

```markdown
BEFORE CODING:
1. Read relevant source files
2. Check existing tests
3. Review similar features
4. Plan changes (write comments first)

WHILE CODING:
1. Use type hints everywhere
2. Add logging (DEBUG for details, INFO for user-facing)
3. Handle errors gracefully
4. Keep functions focused (<50 lines)
5. Document non-obvious logic

AFTER CODING:
1. Run Black and isort
2. Run mypy for type checking
3. Write/update tests
4. Update docstrings
5. Update README if needed
6. Run full test suite
7. Manual testing with real data

COMMIT MESSAGE FORMAT:
feat: Add API-based extraction
fix: Handle empty conversations
docs: Update installation instructions
test: Add tests for JSON exporter
refactor: Simplify message parsing
```

### Debugging Prompts

```markdown
ISSUE: Extraction fails with timeout

DEBUG STEPS:
1. Enable verbose logging: --verbose
2. Check authentication: Test cookie validity
3. Inspect browser: Run with headless=False
4. Add screenshots: page.screenshot() at failure point
5. Check selectors: Verify DOM structure hasn't changed
6. Test with minimal conversation first
7. Increase timeout: --timeout 120

COMMON FIXES:
- Update CSS selectors if Claude UI changed
- Handle new message types
- Add error handling for missing fields
- Implement retry with backoff

ISSUE: Missing artifacts in export

DEBUG STEPS:
1. Check artifact extraction in _extract_from_page()
2. Verify artifact_parser.py logic
3. Log DOM structure of artifact elements
4. Test with known artifact conversation
5. Check Pydantic validation errors

ISSUE: Memory leak with large conversations

DEBUG STEPS:
1. Profile with memory_profiler
2. Check for circular references
3. Ensure generators are used
4. Verify resources are cleaned up
5. Test with progressively larger conversations
```

## ğŸ“Š Project Statistics

- **Total Lines of Code**: ~3,500
- **Python Files**: 15
- **Data Models**: 8 Pydantic classes
- **CLI Commands**: 3 (extract, batch, analyze)
- **Export Formats**: 2 (JSON, Markdown)
- **Dependencies**: 20 production packages
- **Type Coverage**: 100% (all functions typed)
- **Documentation**: README, QUICKSTART, AI_AGENT_PROMPTS

## ğŸ“ Learning Resources

### For New Contributors
1. Read README.md for project overview
2. Read QUICKSTART.md for basic usage
3. Study src/claude_extractor/models/__init__.py for data structures
4. Examine cli.py for user interaction patterns
5. Review hybrid_extractor.py for extraction logic

### Key Abstractions
- **Conversation**: Root container for all conversation data
- **Message**: Single turn (user or assistant)
- **Artifact**: Code/content created during conversation
- **Branch**: Alternative conversation path
- **Extractor**: Strategy for fetching data
- **Exporter**: Strategy for formatting output

### Code Patterns
- Strategy Pattern: Multiple extractors with same interface
- Builder Pattern: Exporters construct complex outputs
- Factory Pattern: Config creates appropriate components
- Repository Pattern: Models separate from persistence

## ğŸš¢ Release Checklist

```markdown
PREPARING VERSION X.Y.Z:

1. Version Bump:
   - Update __version__ in __init__.py
   - Update setup.py
   - Update pyproject.toml

2. Testing:
   - All tests pass
   - Manual test critical paths
   - Test on Python 3.9-3.12

3. Documentation:
   - Update CHANGELOG.md
   - Update README.md
   - Regenerate API docs

4. Package:
   - python -m build
   - twine check dist/*
   - Test install from wheel

5. Release:
   - Git tag vX.Y.Z
   - Push to GitHub
   - Upload to PyPI
   - Create GitHub release

6. Announce:
   - Update project website
   - Post to communities
```

## ğŸ“ Support & Contributing

- **Issues**: GitHub Issues for bugs
- **Discussions**: GitHub Discussions for features/questions
- **Contributing**: See CONTRIBUTING.md (to be created)
- **Code of Conduct**: Be respectful and constructive

---

## ğŸ¯ Next Steps for Development

### High Priority
1. âš ï¸ Implement API extraction (currently uses browser only)
2. âš ï¸ Add comprehensive test suite (currently no tests)
3. âš ï¸ Write authentication manager (currently basic cookie handling)

### Medium Priority
4. ğŸ“Š Enhance conversation analysis with NLP
5. ğŸ“¤ Add more export formats (Obsidian, Notion, HTML)
6. ğŸ” Implement multi-conversation comparison
7. ğŸ“š Write complete documentation with MkDocs

### Low Priority
8. âš¡ Performance optimization (caching, parallelization)
9. ğŸ‘ï¸ Real-time monitoring mode
10. ğŸ”Œ Plugin system for custom exporters
11. ğŸŒ Web UI for extraction management

---

**This project is production-ready for basic extraction but has significant room for enhancement. Use the AI agent prompts above to guide development of new features.**
